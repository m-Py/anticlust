% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/anticlustering-wrapper.R
\name{anticlustering}
\alias{anticlustering}
\title{Anticlustering}
\usage{
anticlustering(features = NULL, distances = NULL, K,
  objective = "distance", method = "sampling", preclustering = FALSE,
  standardize = FALSE, nrep = 10000, categories = NULL,
  parallelize = FALSE, seed = NULL)
}
\arguments{
\item{features}{A numeric vector, matrix or data.frame of data points.
Rows correspond to elements and columns correspond to features. A
vector represents a single numeric feature.}

\item{distances}{Alternative data argument that can be used if
\code{features} is not passed. A N x N matrix representing the
pairwise dissimilarities between N elements. Larger values
indicate higher dissimilarity. Can be an object of class
\code{dist} (e.g., returned by \code{\link{dist}} or
\code{\link{as.dist}}) or a \code{matrix} where the entries of
the upper and lower triangular matrix represent the pairwise
dissimilarities.}

\item{K}{How many anticlusters should be created.}

\item{objective}{The objective to be maximized. The option
"distance" (default) is used to optimize the anticluster
editing objective; the option "variance" is used to optimize
the k-means anticlustering objective. See details.}

\item{method}{One of "exchange", "sampling" or "ilp". See details.}

\item{preclustering}{Boolean, should a preclustering be conducted
before anticlusters are created? Defaults to \code{FALSE} See
details.}

\item{standardize}{Boolean - should the features be standardized
before anticlusters are created? Defaults to \code{FALSE}.
Standardization is done using the function \code{\link{scale}}
using the default settings (mean = 0, SD = 1). This argument
only works when the input data is given via \code{features},
not via \code{distances}.}

\item{nrep}{The number of repetitions for the random sampling
heuristic. This argument only has an effect if \code{method}
is \code{"sampling"}.}

\item{categories}{A vector, data.frame or matrix representing
one or several categorical constraints. These grouping
variables are balanced out across anticlusters. Currently
this functionality is only available in combination with the
sampling and exchange method but not with the ILP approach. If
categorical contraints are employed, the value of the argument
\code{preclustering} will be ignored (that is, there will be no
preclustering).}

\item{parallelize}{Boolean. Indicates whether multiple processors should
be used for the random sampling method.}

\item{seed}{A value to fixate the random seed when using the random
sampling method. When \code{parallelize} is \code{TRUE}, using
this argument is the only way to ensure reproducibility.}
}
\value{
A vector representing the anticluster affiliation of each
    input element.
}
\description{
Create equally-sized groups of elements (anticlusters) that are as
similar as possible.
}
\details{
This function is used to solve »balanced K anticlustering«. That is,
K groups of equal size are created in such a way that all groups are
as similar as possible. Set similarity is assessed using one of
two objective functions:

- k-means *variance* objective, setting \code{objective =
  "variance"}

- cluster editing *distance* objective, setting \code{objective =
  "distance"}

The k-means objective maximizes the variance within anticlusters
(see \code{\link{variance_objective}}). The cluster editing
objective maximizes the sum of pairwise distances within
anticlusters (see \code{\link{distance_objective}}). Maximizing
either of these objectives is used to create similar groups;
minimization of the same objectives leads to a clustering, i.e.,
elements are as similar as possible within a set and as different
as possible between sets. (Clustering is also possible with the function
\code{\link{balanced_clustering}}).

If the argument \code{features} is passed together with
\code{objective = "distance"}, the Euclidean distance between
elements is computed as the basic unit of the anticluster editing
objective. If another measure of dissimilarity is preferred, you
may pass a self-generated dissimiliarity matrix via the argument
\code{distances}.

The optimal anticluster editing objective can be found via integer
linear programming. To this end, set \code{method = "ilp"}. To
obtain an optimal solution, a linear
programming solver must be installed and usable from R. The
`anticlust` package supports the open source GNU linear programming
kit (called from the package \code{Rglpk}) and the commercial
solvers gurobi (called from the package \code{gurobi}) and IBM
CPLEX (called from the package \code{Rcplex}). A license is needed
to use one of the commercial solvers. The optimal solution is
retrieved by setting \code{objective = "distance"},
\code{method = "ilp"} and \code{preclustering = FALSE}. Use this
combination of arguments only for small problem sizes (maybe <= 30
elements).

To relax the optimality condition, it is possible to set the
argument \code{preclustering = TRUE}. In this case, the anticluster
editing objective is still optimized using integer linear
programming, but a preprocessing forbids very similar elements to
be assigned to the same anticluster. This approach can be used to
work on larger problem instances and the solution is usually still
optimal or very close to optimal.

In addition to the exact approach---that is only feasible for small
N---the function employs two heuristic approaches. The
first option is repeated random sampling: Across a specified
number of runs, anticlusters are assigned randomly and the best
assignment is returned. The second is the exchange method: From an
initial anticluster assignment, items are swapped systematically in
such a way that the similarity is improved in the best way that is
possible (see Späth, 1986). Note, that the number of swaps grows
quadratically with input size so that the random sampling method
is recommended for large N.

The random sampling approach may also incorporate a
preclustering that prevents grouping very similar elements into the
same anticluster. Preclustering (for the exact and random sampling approach)
is performed by a call to \code{\link{balanced_clustering}} where the
argument \code{K} is set to the number of elements divided by the
number of anticlusters that are to be created (actually, this is not
exactly what happens internally, but it is equivalent).

For the random sampling method, the output will
vary between function calls. To make a computation results
reproducible, you can use the argument \code{seed} -- a specific
value will produce the same results when the function is called with
the same input parameters. Note that the
same seed will produce different results when the parameter
\code{parallelize} is varied. For the parallel computation, the
random seed is set using the function
\code{\link[parallel]{clusterSetRNGStream}}; otherwise, the function
\code{\link{set.seed}} is called.
}
\examples{

## Use anticlustering on the iris data set. Create sets of plants
## that are as similar as possible with regard to all four features
## of the iris plants

data(iris)
head(iris[, -5]) # these features are made similar across sets

# Optimize the variance criterion (create similar feature means)
anticlusters <- anticlustering(
  iris[, -5],
  K = 3,
  objective = "variance",
  method = "exchange"
)
# Compare feature means by anticluster
by(iris[, -5], anticlusters, function(x) round(colMeans(x), 2))

# Optimize the cluster editing objective using random sampling
# (cluster editing maximizes total pairwise similarity of plants,
# not just the feature means)
anticlusters <- anticlustering(
  iris[, -5],
  K = 3,
  method = "sampling",
  objective = "distance",
  nrep = 10000
)

# Incorporate categorical restrictions:
anticlusters <- anticlustering(
  iris[, -5],
  K = 2,
  categories = iris[, 5],
  method = "sampling",
  nrep = 10
)
table(iris[, 5], anticlusters)

}
\references{
Grötschel, M., & Wakabayashi, Y. (1989). A cutting plane algorithm
for a clustering problem. Mathematical Programming, 45, 59-96.

Böcker, S., Briesemeister, S., & Klau, G. W. (2011). Exact algorithms
for cluster editing: Evaluation and experiments. Algorithmica, 60,
316-334.

Späth, H. (1986). Anticlustering: Maximizing the variance criterion.
Control and Cybernetics, 15, 213-218.
}
